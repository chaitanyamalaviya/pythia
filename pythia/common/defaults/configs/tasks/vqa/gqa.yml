task_attributes:
    vqa:
        datasets:
        - gqa
        dataset_attributes:
            gqa:
                data_root_dir: ../data
                data_folder: GQA_PP
                image_depth_first: false
                fast_read: false
                features_max_len: 100
                imdb_files:
                  train:
                    - imdb/gqa/imdb_train_balanced.npy
                  val:
                    - imdb/gqa/imdb_val_balanced.npy
                  test:
                    - imdb/gqa/imdb_test_balanced.npy
                scene_graphs:
                  train:
                    - GQA/sceneGraphs/train_sceneGraphs.json
                  val:
                    - GQA/sceneGraphs/val_sceneGraphs.json
                image_features:
                  objects:
                    - objects/
                  spatial:
                    - GQA_PP/spatial/
                object_classes:
                  - gqa_image_classes.json
                processors:
                    text_processor:
                        type: vocab
                        params:
                          max_length: 14
                          vocab:
                            type: intersected
                            embedding_name: glove.6B.300d
                            vocab_file: GQA_PP/vocabulary_gqa.txt
                          preprocessor:
                            type: simple_sentence
                            params: {}
                    answer_processor:
                        type: vqa_answer
                        params:
                            num_answers: 10
                            # Vocab file is relative to [data_root_dir]/[data_folder]
                            vocab_file: GQA_PP/answers_gqa.txt
                            preprocessor:
                                type: simple_word
                                params: {}
